name: Run scraper and commit CSV

on:
  schedule:
    - cron: "0 */12 * * *"   # every 12 hours
  workflow_dispatch: {}       # button for non-automated run

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          SERPER_KEY: ${{ secrets.SERPER_KEY }}
          SCRAPINGDOG_API_KEY: ${{ secrets.SCRAPINGDOG_API_KEY }}
          JOBS_MERGED_CSV: merged_jobs.csv
        run: |
          python main.py

      - name: Commit CSV back
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          git config user.name "automation-bot"
          git config user.email "bot@example.com"
          git add merged_jobs.csv
          git commit -m "Update merged_jobs.csv (CI)" || echo "Nothing to commit"
          git push https://x-access-token:${GH_TOKEN}@github.com/${{ github.repository }} HEAD:${{ github.ref_name }}
